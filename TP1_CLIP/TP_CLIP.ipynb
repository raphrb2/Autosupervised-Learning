{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfz7BSY7SP5P"
      },
      "source": [
        "# TP : apprentissage multimodal\n",
        "\n",
        "\n",
        "Dans ce TP, nous allons utiliser le modèle d'apprentissage, FashionCLIP, pré-entraîné sur des images ainsi que des descriptions en langage naturel. Plus particulièrement, nous allons considérer deux cas d'usage :\n",
        "\n",
        "*   **Moteur de recherche d'images :** il s'agit de trouver, à partir d'une requête en langage naturel, l'image correspondante.\n",
        "\n",
        "*   **Classification zero-shot :** il s'agit simplement de construire un classifieur d'images (faire correspondre un label à une image).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ3s403V5LKs"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Nous allons dans un premier temps télécharger les données. Celles-ci provienennt de [Kaggle](https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLyWzNhJwoS2"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install gdown\n",
        "!gdown \"1igAuIEW_4h_51BG1o05WS0Q0-Cp17_-t&confirm=t\"\n",
        "!unzip data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dzpM2oASwM6"
      },
      "source": [
        "### Modèle FashionCLIP\n",
        "\n",
        "Nous allons également télécharger le modèle pré-entraîné."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyBLvPLgSx5h"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U fashion-clip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WijCpqbIyH7T"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "#sys.path.append(\"fashion-clip/\")\n",
        "from fashion_clip.fashion_clip import FashionCLIP\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import *\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xEzYFUbydJY"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "fclip = FashionCLIP('fashion-clip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViPu0y8C0UfS"
      },
      "source": [
        "FashionCLIP, à l'instar de CLIP, crée un espace vectoriel partagé pour les images et le texte. Cela permet de nombreuses applications, telles que la recherche (trouver l'image la plus similaire à une requête donnée) ou la classification zero-shot.\n",
        "\n",
        "Il y a principalement deux composants : un encodeur d'image (pour générer un vecteur à partir d'une image) et un encodeur de texte (pour générer un vecteur à partir d'un texte).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oc2jvxPpFWQ"
      },
      "source": [
        "\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/0*FLNMtW6jK51fm7Og\"  width=\"400\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsPVQgNphwFX"
      },
      "source": [
        "Nous allons télécharger les données que nous allons ensuite nettoyer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "9emW_P2fhxSW",
        "outputId": "54f24f03-095a-4967-dffa-0356509e8f26"
      },
      "outputs": [],
      "source": [
        "articles = pd.read_csv(\"data_for_fashion_clip/articles.csv\")\n",
        "\n",
        "# Supprimer les éléments ayant la même description\n",
        "subset = articles.drop_duplicates(\"detail_desc\").copy()\n",
        "\n",
        "# Supprimer les images dont la catégrie n'est pas renseignée\n",
        "subset = subset[~subset[\"product_group_name\"].isin([\"Unknown\"])]\n",
        "\n",
        "# Garder seulement les descriptions dont la longueur est inférieure à 40 tokens\n",
        "subset = subset[subset[\"detail_desc\"].apply(lambda x : 4 < len(str(x).split()) < 40)]\n",
        "\n",
        "# Supprimer les articles qui ne sont pas suffisamment fréquents dans le jeu de données\n",
        "most_frequent_product_types = [k for k, v in dict(Counter(subset[\"product_type_name\"].tolist())).items() if v > 10]\n",
        "subset = subset[subset[\"product_type_name\"].isin(most_frequent_product_types)]\n",
        "\n",
        "subset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "subset.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kTiCnV7Nko5L",
        "outputId": "492b1053-7a82-45dc-f816-83b206e98779"
      },
      "outputs": [],
      "source": [
        "subset.to_csv(\"subset_data.csv\", index=False)\n",
        "f\"Il y a {len(subset)} éléments dans le dataset\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcLNKhgD75pm"
      },
      "source": [
        "## Moteur de recherche d'images\n",
        "\n",
        "Constuire un moteur de recherche qui permet, à partir d'une description en langage naturel, de récupérer l'image correspondante. Mesurer ses performances (précision).\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*cnKHgLAumVyuHuK9pkqr7A.gif\"  width=\"800\">\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "68d2dd8c312b48f3b32489b2c017783b",
            "1cd8534529df4c0ba1d8904574477230",
            "23ce399a40124d0baed9e05999c34209",
            "89c2ba7eb38f4e63b4ed4608917f67a1",
            "e8da7afb1e6044928eb17029920dc514",
            "5784019791aa43e5a7d79b1d77901b42",
            "352fa0b2147d42c88066f04ebddcdd2f",
            "ac58fba95c3c4c12b9f8cd5d2d4b3cfa",
            "00cbbc720bfb4a3fa6625de55545bf2a",
            "2b636b702c014d6f8546e8573201fe7f",
            "9c09bc07398c43c7bd80798847de0ca8"
          ]
        },
        "id": "cla9wews4eZg",
        "outputId": "52a7ae35-5be7-484a-ac40-3270321fa675"
      },
      "outputs": [],
      "source": [
        "images = [\"data_for_fashion_clip/\" + str(k) + \".jpg\" for k in subset[\"article_id\"].tolist()]\n",
        "texts = subset[\"detail_desc\"].tolist()\n",
        "\n",
        "# Créer les représentations vectorielles (embeddings) des images et des descriptions.\n",
        "image_embeddings = fclip.encode_images(images, batch_size=32)\n",
        "text_embeddings = fclip.encode_text(texts, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5TKhC_NeKp3",
        "outputId": "001f3e91-09d3-4dca-bf1e-a7af4213001c"
      },
      "outputs": [],
      "source": [
        "print(image_embeddings.shape)\n",
        "print(text_embeddings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_closest_image(text_embeddings, image_embeddings,images, text_idx=0, top_k=5):\n",
        "    embedded_txt = text_embeddings[text_idx]\n",
        "    # pour chaque image, on calcule cosine similarity\n",
        "    similarities = []\n",
        "    for image_embedding in image_embeddings:\n",
        "        similarities.append(np.dot(embedded_txt, image_embedding) / (np.linalg.norm(embedded_txt) * np.linalg.norm(image_embedding)))\n",
        "    # on recupère les top_k images les plus proches\n",
        "    closest_image_idxs = np.argsort(similarities)[::-1][:top_k]\n",
        "    return closest_image_idxs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# calcul de l'accuracy du modèle\n",
        "def compute_accuracy(text_embeddings, image_embeddings, images):\n",
        "    accuracy = 0\n",
        "    for idx, text_embedding in enumerate(text_embeddings):\n",
        "        closest_image_idxs = find_closest_image(text_embeddings, image_embeddings, images, text_idx=idx, top_k=5)\n",
        "        closest_images = [images[k] for k in closest_image_idxs]\n",
        "        if images[idx] in closest_images:\n",
        "            accuracy += 1\n",
        "    return accuracy / len(text_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "accuracy = compute_accuracy(text_embeddings, image_embeddings, images)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87URDy7xh65d"
      },
      "source": [
        "# Classification zero-shot\n",
        "\n",
        "Construite un classsifieur d'images (prédire le label d'une image). Mesurer ses performances.\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*No6ZONpQMIcfFaNMOI5oNw.gif\"  width=\"800\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_closest_label(image_embeddings, text_embeddings, labels, image_idx=0, top_k=5):\n",
        "    embedded_img = image_embeddings[image_idx]\n",
        "    # pour chaque texte, calcul de la cosine similarity\n",
        "    similarities = []\n",
        "    for text_embedding in text_embeddings:\n",
        "        similarities.append(np.dot(embedded_img, text_embedding) / (np.linalg.norm(embedded_img) * np.linalg.norm(text_embedding)))\n",
        "    # reucuperation des top_k labels les plus proches\n",
        "    closest_label_idxs = np.argsort(similarities)[::-1][:top_k]\n",
        "    return [labels[k] for k in closest_label_idxs]\n",
        "\n",
        "def compute_label_accuracy(image_embeddings, text_embeddings, labels):\n",
        "    accuracy = 0\n",
        "    for idx, image_embedding in enumerate(image_embeddings):\n",
        "        closest_labels = find_closest_label(image_embeddings, text_embeddings, labels, image_idx=idx, top_k=5)\n",
        "        if labels[idx] in closest_labels:\n",
        "            accuracy += 1\n",
        "    return accuracy / len(image_embeddings)\n",
        "\n",
        "# accuracy\n",
        "label_accuracy = compute_label_accuracy(image_embeddings, text_embeddings, texts)\n",
        "print(f\"Label Accuracy: {label_accuracy}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "dev",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "polyglot_notebook": {
      "kernelInfo": {
        "defaultKernelName": "csharp",
        "items": [
          {
            "aliases": [],
            "name": "csharp"
          }
        ]
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00cbbc720bfb4a3fa6625de55545bf2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1cd8534529df4c0ba1d8904574477230": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5784019791aa43e5a7d79b1d77901b42",
            "placeholder": "​",
            "style": "IPY_MODEL_352fa0b2147d42c88066f04ebddcdd2f",
            "value": "Map: 100%"
          }
        },
        "23ce399a40124d0baed9e05999c34209": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac58fba95c3c4c12b9f8cd5d2d4b3cfa",
            "max": 3104,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00cbbc720bfb4a3fa6625de55545bf2a",
            "value": 3104
          }
        },
        "2b636b702c014d6f8546e8573201fe7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "352fa0b2147d42c88066f04ebddcdd2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5784019791aa43e5a7d79b1d77901b42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68d2dd8c312b48f3b32489b2c017783b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1cd8534529df4c0ba1d8904574477230",
              "IPY_MODEL_23ce399a40124d0baed9e05999c34209",
              "IPY_MODEL_89c2ba7eb38f4e63b4ed4608917f67a1"
            ],
            "layout": "IPY_MODEL_e8da7afb1e6044928eb17029920dc514"
          }
        },
        "89c2ba7eb38f4e63b4ed4608917f67a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b636b702c014d6f8546e8573201fe7f",
            "placeholder": "​",
            "style": "IPY_MODEL_9c09bc07398c43c7bd80798847de0ca8",
            "value": " 3104/3104 [00:00&lt;00:00, 3230.61 examples/s]"
          }
        },
        "9c09bc07398c43c7bd80798847de0ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac58fba95c3c4c12b9f8cd5d2d4b3cfa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8da7afb1e6044928eb17029920dc514": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
